{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Algoritmos de regresión\n",
    "## Requisitos\n",
    "## Introducción\n",
    "## Regresión lineal (OLS)\n",
    "### Definición\n",
    "Como sabemos, los modelos de conocimiento en aprendizaje supervisado pueden ser entendidos como funciones que reciben una entrada, la cual es un vector con los valores de los atributos, y devuelven una salida, que se trata de un valor estimado para\n",
    "la clase. El algoritmo OLS –_ordinary least squares, en inglés_ –es capaz de generar un modelo que consta de una combinación lineal de los atributos. En concreto, el modelo que genera OLS puede expresarse matemáticamente del siguiente modo:\n",
    "\n",
    "$$𝑦̂=𝑤_0 + 𝑤_1 · 𝑥_1 + ⋯ + 𝑤_𝑝 · 𝑥_𝑝$$\n",
    "\n",
    "En la anterior ecuación, $𝑦̂$ es el valor predicho por el algoritmo, $x_1, ..., x_p$ son los valores de los atributos, $𝑤_1, ..., 𝑤_𝑝∈𝑅$ son los coeficientes del modelo y $w_0$ es el término independiente de la combinación lineal.\n",
    "\n",
    "Una vez explicado el modelo de OLS, vamos a explicar la función de coste que emplea para optimizar los coeficientes del modelo y así, conseguir que sea capaz de estimar con mayor precisión la variable de salida. \n",
    "\n",
    "La función objetivo o función de coste es aquella que evalua cómo de buena es la posible solución. En el caso de OLS, la función objetivo que usa es [MSE (mean squared error)](https://www.iartificial.net/error-cuadratico-medio-para-regresion/), y consiste en encontrar aquellos valores para los coeficientes $𝑤_0, ..., 𝑤_𝑝$ que minimizan el error. \n",
    "![Reducición del error cuadrático medio](https://miro.medium.com/max/1400/1*1pBRuJzxj4oqwnDx0Ygf1w.png \"Reducición del error cuadrático medio\")\n",
    "\n",
    "### Ventajas\n",
    "+ La simplicidad del modelo.\n",
    "+ La fácil interpretabilidad del modelo.\n",
    "+ La gran eficacia en problemas de índole lineal.\n",
    "+ El tiempo de ejecución del entrenamiento muy razonable.\n",
    "+ El tiempo de ejecución de la predicción casi instantáneo.\n",
    "\n",
    "### Desventajas\n",
    "+ La independencia entre los atributos.\n",
    "+ La distribución normal de los datos.\n",
    "+ La relación lineal entre los atributos y la clase.\n",
    "\n",
    "\n",
    "### Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión logística\n",
    "### Definición\n",
    "La regresión logística (LOGR) es un algoritmo de aprendizaje automático que se utiliza sobre todo para los problemas de clasificación, aunque también se puede emplear en problemas de regresión. Es un algoritmo de análisis predictivo y se basa en el concepto de probabilidad. \n",
    "\n",
    "LOGR utiliza una función definida como función sigmoide y devuelve un valor entre 0 y 1 dependiendo del valor de entrada que reciba. Pero claro, esto sólo es útil si tenemos que predecir dos valores, ¿pero que pasaría si tenemos que predecir _n_ valores? Para resolver este problema se lleva a cabo la descomposición del problema original en _m_ subproblemas, del tipo binario (la función sigmoide). A este proceso se le define como _una contra todos o [one vs rest (OvR)](https://machinelearningmastery.com/one-vs-rest-and-one-vs-one-for-multi-class-classification/)_.\n",
    "\n",
    "La división en subproblemas binarios de tipo _OvR_ permite realizar una regresión usando la regresión logística más simple. Cada modelo, una vez entrenado, aprendería una frontera lineal de decisión que enfrenta cada target con los restantes, tal como se muestra en la figura para un problema con 3 targets. \n",
    "\n",
    "![One vs rest (OvR)](../assets/img/OvR.png \"One vs rest (OvR)\")\n",
    "\n",
    "\n",
    "### Ventajas\n",
    "+ La simplicidad del modelo.\n",
    "+ La fácil interpretabilidad de las predicciones.\n",
    "+ El tiempo de ejecución del entrenamiento muy razonable.\n",
    "+ El tiempo de ejecución de la predicción casi instantáneo.\n",
    "\n",
    "### Desventajas\n",
    "+ La independencia entre los atributos.\n",
    "+ La excesiva simplicidad del modelo.\n",
    "\n",
    "### Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árboles de decisión\n",
    "### Definición\n",
    "### Ventajas\n",
    "### Desventajas\n",
    "### Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vecinos más cercanos\n",
    "### Definición\n",
    "El algoritmo de vecinos más cercanos –_k nearest neighbors(KNN), en inglés_ –se basa en la idea de que ejemplos similares en sus atributos presentan también un comportamiento similar en el valor de sus clases. La idea consiste en producir como predicción el promedio de las clases de los ejemplos de entrenamiento más parecidos (vecinos) al ejemplo de prueba que hay que predecir. Definiremos qué debe considerarse más parecido, aspecto que afecta a la eficacia del algoritmo.\n",
    "\n",
    "Para llevar a cabo las predicciones, el algoritmo KNN clásico se basa en los dos siguientes elementos configurables: el número $𝑘∈𝑁$ de vecinos más cercanos y la función de distancia d. Con respecto a esta última, existen numerosas funciones de distancia propuestas en la literatura. En esta sección usaremos la distancia de Minkowski, la cual se define así:$$Minkowski(𝑒_𝑖,𝑒_𝑗)=(\\sum_{d=1}^{p}|x_{i,d} - x_{j,d}|^q)^\\frac{1}{q}$$\n",
    "\n",
    "La función de distancia es un hiperparámetro de KNN que afecta en gran medida a la bondad de las predicciones. Es cierto, que cada problema requiere una función de distancia más adecuada a la naturaleza y distribución de los datos, pero en la mayoría de los casos, la distancia más utilizada es la euclídea, cuando el valor de p es igual a 2\n",
    "![Distancia de Minkowski](https://leovan.me/images/cn/2019-01-01-similarity-and-distance-measurement/2D-unit-balls.png)\n",
    "\n",
    "### Ventajas\n",
    "+ La simplicidad del modelo.\n",
    "+ La fácil interpretabilidad de las predicciones.\n",
    "+ El tiempo de ejecución del entrenamiento prácticamente nulo.\n",
    "\n",
    "### Desventajas\n",
    "+ El tiempo de ejecución alto en la fase de predicción.\n",
    "+ La falta de generalización.\n",
    "+ La necesidad de atributos relevantes y en igual escala.\n",
    "\n",
    "### Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
